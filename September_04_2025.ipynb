{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "hlOVuX6AEx5i",
        "outputId": "2c906834-c52f-4d12-9534-39051cd8bed4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid character '–' (U+2013) (ipython-input-3309219481.py, line 9)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3309219481.py\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    *   1783: Hot air balloons – Montgolfier brothers.\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '–' (U+2013)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"In-Class Notes\n",
        "\n",
        "Topic: Introduction to Autonomous Drones\n",
        "\n",
        "1. History & Evolution of Aerial Vehicles\n",
        "\n",
        "*   Ancient roots: Icarus (Greek myth), Weimanika Shastra (India).\n",
        "*   Early milestones:\n",
        "    *   1783: Hot air balloons – Montgolfier brothers.\n",
        "    *   1852: First powered airship – Henri Giffard.\n",
        "    *   Otto Lilienthal – gliders, bird-like designs.\n",
        "    *   Wright brothers – first controlled powered flight (1906).\n",
        "*   Modern drones = Mechanics + Electronics + Computer science.\n",
        "\n",
        "2. Physics of Flight\n",
        "\n",
        "*   4 Key Forces:\n",
        "    *   Lift → wings/propellers, Bernoulli’s principle.\n",
        "    *   Thrust → engines/propellers.\n",
        "    *   Weight → gravity, acts downward.\n",
        "    *   Drag → resistance, opposes motion.\n",
        "*   Axes of motion:\n",
        "    *   Roll (longitudinal), Pitch (lateral), Yaw (normal).\n",
        "*   Quadcopter control = adjusting propeller speeds.\n",
        "*   Stability concepts: Center of Gravity (CG), Center of Pressure (CP).\n",
        "\n",
        "3. Drone Configurations\n",
        "\n",
        "*   Monocopter → simple, limited control.\n",
        "*   Bicopter → two props, yaw control.\n",
        "*   Tricopter → 3 props, better load capacity.\n",
        "*   Quadcopter → most common, stable.\n",
        "*   Hexacopter → 6 props, heavier loads, motor-failure tolerance.\n",
        "*   Octocopter → 8 props, high power + payload.\n",
        "*   EVTOL fixed-wing → hybrid endurance drones.\n",
        "*   Ornithopters → biomimicry, flapping wings.\n",
        "\n",
        "4. Basic Components\n",
        "\n",
        "*   Propellers → thrust/lift via airflow.\n",
        "*   BLDC motors → permanent magnet motors, KV rating = RPM/Volt.\n",
        "*   ESC (Electronic Speed Controller) → adjusts motor speed (PWM signals).\n",
        "*   Flight Controller → \"brain\" (Pixhawk, Orange Cube).\n",
        "*   Frame → carbon fiber/plastic/aluminum.\n",
        "*   Battery → LiPo/Li-ion; mAh (capacity), Voltage (cells), C-rating (discharge).\n",
        "*   Power Distribution Board → connects battery to motors/electronics.\n",
        "*   GPS Module → positioning/navigation (limitations: jamming).\n",
        "*   Transmitter & Receiver → remote communication, 2.4 GHz band.\n",
        "\n",
        "5. Drone Design Process\n",
        "\n",
        "*   Define requirements (payload, endurance, range).\n",
        "*   Estimate total weight.\n",
        "*   Select thrust-to-weight ratio (e.g., 2:1 for surveillance drones).\n",
        "*   Choose frame type (quad/hexa/octa).\n",
        "*   Calculate thrust per motor.\n",
        "*   Select motors & propellers via market survey.\n",
        "*   Choose ESC based on current & voltage.\n",
        "*   Select battery → matches current & flight time.\n",
        "*   Pick flight controller & transmitter.\n",
        "*   Balance weight, stability, endurance, cost.\n",
        "*   Case Study → Agricultural drone carrying 15 kg, 15 min endurance, 5 km range.\n",
        "\n",
        "6. Key Takeaways\n",
        "\n",
        "*   Drones = blend of aerospace + AI + electronics.\n",
        "*   Design = iterative & practical (balance performance vs. cost).\n",
        "*   Stability & power management are crucial.\n",
        "*   Indigenous subsystems = sustainability & competitiveness.\n",
        "*   Strong link between physics (forces, aerodynamics) and practical design choices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning and Deep Learning"
      ],
      "metadata": {
        "id": "TvRn7aBFJqiZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "030d0f76"
      },
      "source": [
        "Here are examples demonstrating the basic usage of Scikit-learn, TensorFlow, and PyTorch for a simple task like linear regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e60715b8"
      },
      "source": [
        "### Scikit-learn Example: Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fP9y3bX0o2vA",
        "outputId": "4dcb2787-3e95-4351-fe53-4c8de0a2e719"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "X = np.array([[1], [2], [3], [4]])\n",
        "y = np.array([2, 4, 5, 4])\n",
        "\n",
        "# Create and train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make a prediction\n",
        "prediction = model.predict([[5]])\n",
        "print(f\"Scikit-learn Prediction: {prediction[0]:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scikit-learn Prediction: 5.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "015649f0"
      },
      "source": [
        "**Explanation:**\n",
        "This code performs a simple linear regression using Scikit-learn. It defines input data `X` and output data `y`, creates a `LinearRegression` model, trains it using the `fit` method, and then makes a prediction for a new input using the `predict` method.\n",
        "\n",
        "**What differentiates Scikit-learn:**\n",
        "*   **Ease of Use:** Simple and consistent API for various algorithms.\n",
        "*   **Classical ML Focus:** Primarily for traditional machine learning tasks.\n",
        "*   **Great for Beginners and Prototyping:** Excellent for getting started and quick experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cde17c8b"
      },
      "source": [
        "### TensorFlow Example: Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN7v2U3k0j9I",
        "outputId": "2ac0ac3d-7863-4ec3-e6bc-3ea1801333d7"
      },
      "source": [
        "#deep learing\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "X = np.array([[1.], [2.], [3.], [4.]], dtype=np.float32)\n",
        "y = np.array([2., 4., 5., 4.], dtype=np.float32)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=1, input_shape=[1])\n",
        "])\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.optimizers.Adam(0.1))\n",
        "model.fit(X, y, epochs=100, verbose=0)\n",
        "\n",
        "# Make a prediction\n",
        "prediction = model.predict(tf.constant([[5.]], dtype=tf.float32))\n",
        "print(f\"TensorFlow Prediction: {prediction[0][0]:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "TensorFlow Prediction: 5.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92e2ac68"
      },
      "source": [
        "**Explanation:**\n",
        "This example uses TensorFlow with the Keras API to build and train a simple linear regression model. It defines a sequential model with a dense layer, compiles it with a loss function and optimizer, trains it using the `fit` method, and makes a prediction with `predict`.\n",
        "\n",
        "**What differentiates TensorFlow:**\n",
        "*   **Production Readiness:** Strong support for deployment and scaling.\n",
        "*   **Static and Dynamic Graphs:** Offers flexibility in model building.\n",
        "*   **Comprehensive Ecosystem:** Tools for data processing, deployment, and more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52a584a8"
      },
      "source": [
        "### PyTorch Example: Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ9t0I1h6g5F",
        "outputId": "cf676503-d0af-495a-d58f-0a920c850e49"
      },
      "source": [
        "#deep learing\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "X = torch.tensor([[1.], [2.], [3.], [4.]], dtype=torch.float32)\n",
        "y = torch.tensor([[2.], [4.], [5.], [4.]], dtype=torch.float32)\n",
        "\n",
        "# Define the model\n",
        "model = nn.Linear(1, 1)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Train the model\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    outputs = model(X)\n",
        "    loss = criterion(outputs, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Make a prediction\n",
        "with torch.no_grad():\n",
        "    prediction = model(torch.tensor([[5.]], dtype=torch.float32))\n",
        "    print(f\"PyTorch Prediction: {prediction.item():.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Prediction: 6.09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23578f92"
      },
      "source": [
        "**Explanation:**\n",
        "This PyTorch example demonstrates building and training a linear regression model. It defines the model as an `nn.Linear` layer, sets up a loss function (`MSELoss`) and optimizer (`SGD`), and trains the model in a loop by performing forward passes, calculating the loss, backpropagating gradients, and updating weights.\n",
        "\n",
        "**What differentiates PyTorch:**\n",
        "*   **Pythonic and Flexible:** More intuitive and easier for dynamic model building.\n",
        "*   **Research-Oriented:** Popular in the research community due to its flexibility.\n",
        "*   **Dynamic Computation Graph:** Allows for more dynamic and interactive development."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cab235f1",
        "outputId": "bc51a1d0-1bbd-43df-f348-4754ba145072"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "X = np.array([[1.], [2.], [3.], [4.]], dtype=np.float32)\n",
        "y = np.array([2., 4., 5., 4.], dtype=np.float32)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=1, input_shape=[1])\n",
        "])\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.optimizers.Adam(0.1))\n",
        "model.fit(X, y, epochs=100, verbose=0)\n",
        "\n",
        "# Make a prediction\n",
        "prediction = model.predict(tf.constant([[5.]], dtype=tf.float32))\n",
        "print(f\"TensorFlow Prediction: {prediction[0][0]:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "TensorFlow Prediction: 5.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2140577"
      },
      "source": [
        "## Scaling Techniques in Machine Learning\n",
        "\n",
        "Scaling is an important preprocessing step to ensure that features are on a similar scale, which can improve the performance of many machine learning algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66f1cf5c"
      },
      "source": [
        "### 1. Normalization (Min-Max Scaling)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "286080bf",
        "outputId": "94547643-c802-4ec8-df4a-07890f908816"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Sample data (features)\n",
        "X = np.array([[0], [2], [300], [5], [50]])\n",
        "\n",
        "# Apply Min-Max Scaling\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(\"Original Data:\\n\", X)\n",
        "print(\"Normalized Data (Min-Max Scaling):\\n\", X_scaled)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data:\n",
            " [[  0]\n",
            " [  2]\n",
            " [300]\n",
            " [  5]\n",
            " [ 50]]\n",
            "Normalized Data (Min-Max Scaling):\n",
            " [[0.        ]\n",
            " [0.00666667]\n",
            " [1.        ]\n",
            " [0.01666667]\n",
            " [0.16666667]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c125745a"
      },
      "source": [
        "This scales features to a fixed range, usually 0 to 1.\n",
        "It is sensitive to outliers, which can be compressed into a small range."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14c33867"
      },
      "source": [
        "### 2. Standardization (Z-score Scaling)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7f09da9",
        "outputId": "5285465e-33e1-46aa-adc1-b11a0f1a0ef5"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Sample data (features)\n",
        "X = np.array([[0], [2], [3], [4], [10]])\n",
        "\n",
        "# Apply Standardization\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(\"Original Data:\\n\", X)\n",
        "print(\"Standardized Data (Z-score Scaling):\\n\", X_scaled)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data:\n",
            " [[ 0]\n",
            " [ 2]\n",
            " [ 3]\n",
            " [ 4]\n",
            " [10]]\n",
            "Standardized Data (Z-score Scaling):\n",
            " [[-1.12744258]\n",
            " [-0.53405175]\n",
            " [-0.23735633]\n",
            " [ 0.05933908]\n",
            " [ 1.83951157]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b55b41b"
      },
      "source": [
        "This scales features to have a mean of 0 and a standard deviation of 1.\n",
        "It is less affected by outliers compared to Min-Max Scaling.\n",
        "\n",
        "If an original data point is exactly the average, its standardized value will be 0.\n",
        "If an original data point is above the average, its standardized value will be positive. The larger the positive number, the further above the average it is.\n",
        "\n",
        "If an original data point is below the average, its standardized value will be negative. The larger the negative number (in absolute value), the further below the average it is.\n",
        "\n",
        "So, the standardized data is just a transformed version of the original data, where the values now represent their position relative to the mean of the original data, measured in units of the original data's standard deviation. The shape of the data's distribution stays the same, but it's shifted and scaled so the new average is 0 and the new spread (standard deviation) is 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "250059aa"
      },
      "source": [
        "### 3. Quantile Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3340fc0",
        "outputId": "09ecd370-aee0-4d10-d917-8e041dccb8b5"
      },
      "source": [
        "from sklearn.preprocessing import QuantileTransformer\n",
        "import numpy as np\n",
        "\n",
        "# Sample data (features)\n",
        "X = np.array([[1], [2], [3], [4], [10], [100], [200]]) # More varied data\n",
        "\n",
        "# Apply Quantile Transformation (to normal distribution)\n",
        "scaler = QuantileTransformer(output_distribution='normal', n_quantiles=5)\n",
        "X_trans = scaler.fit_transform(X)\n",
        "\n",
        "print(\"Original Data:\\n\", X)\n",
        "print(\"Quantile Transformed Data (Normal Distribution):\\n\", X_trans)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data:\n",
            " [[  1]\n",
            " [  2]\n",
            " [  3]\n",
            " [  4]\n",
            " [ 10]\n",
            " [100]\n",
            " [200]]\n",
            "Quantile Transformed Data (Normal Distribution):\n",
            " [[-5.19933758]\n",
            " [-0.96742157]\n",
            " [-0.4307273 ]\n",
            " [ 0.        ]\n",
            " [ 0.07379127]\n",
            " [ 0.94466959]\n",
            " [ 5.19933758]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cc5f91e"
      },
      "source": [
        "This transforms features to follow a uniform or normal distribution.\n",
        "It is useful for handling skewed data and is robust to outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "166d1811"
      },
      "source": [
        "### When not to scale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c657f29"
      },
      "source": [
        "Scaling is generally not required for tree-based algorithms like Decision Trees, Random Forests, and gradient boosting models (e.g., XGBoost, CatBoost). These algorithms are not sensitive to the scale of features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b861f72"
      },
      "source": [
        "## Encoding Categorical Features\n",
        "\n",
        "Many machine learning algorithms require numerical input. Categorical features (like \"color\" or \"city\") need to be converted into numerical representations through a process called encoding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9af1710"
      },
      "source": [
        "### 1. Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f84bbbc",
        "outputId": "1b5b9db8-dc44-43f1-cbb8-88e0b29e154b"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Sample categorical data\n",
        "y_cat = np.array(['red', 'blue', 'green', 'red', 'blue'])\n",
        "\n",
        "# Apply Label Encoding\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y_cat)\n",
        "\n",
        "print(\"Original Categorical Data:\\n\", y_cat)\n",
        "print(\"Label Encoded Data:\\n\", y_encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Categorical Data:\n",
            " ['red' 'blue' 'green' 'red' 'blue']\n",
            "Label Encoded Data:\n",
            " [2 0 1 2 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "071392bc"
      },
      "source": [
        "Assigns a unique integer to each category. Suitable for ordinal data or as a first step for tree-based models.\n",
        "Can impose artificial order on non-ordinal data, which can negatively impact some models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b050677"
      },
      "source": [
        "### 2. One-Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57f45fd1",
        "outputId": "552d7640-60b1-4ce8-af85-32f2ea4fa033"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Sample categorical data\n",
        "X_cat = np.array([['red'], ['blue'], ['green'], ['red'], ['blue']])\n",
        "\n",
        "# Apply One-Hot Encoding\n",
        "# sparse=False returns a dense NumPy array\n",
        "ohe = OneHotEncoder(sparse_output=False)\n",
        "X_ohe = ohe.fit_transform(X_cat)\n",
        "\n",
        "print(\"Original Categorical Data:\\n\", X_cat)\n",
        "print(\"One-Hot Encoded Data:\\n\", X_ohe)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Categorical Data:\n",
            " [['red']\n",
            " ['blue']\n",
            " ['green']\n",
            " ['red']\n",
            " ['blue']]\n",
            "One-Hot Encoded Data:\n",
            " [[0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ea45d6e"
      },
      "source": [
        "Creates a binary column for each category. Ideal for nominal data to avoid imposing order.\n",
        "Can lead to a high-dimensional feature space if there are many unique categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc58eca5"
      },
      "source": [
        "### 3. Ordinal Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2a5d72a",
        "outputId": "7a9cda81-19bb-446b-8bbe-669a6ff79892"
      },
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Sample ordinal categorical data (e.g., size)\n",
        "X_ord_cat = np.array([['small'], ['medium'], ['large'], ['medium'], ['small']])\n",
        "\n",
        "# Define the order of categories\n",
        "categories_order = [['medium', 'small', 'large']]\n",
        "\n",
        "# Apply Ordinal Encoding\n",
        "ord_enc = OrdinalEncoder(categories=categories_order)\n",
        "X_ord_encoded = ord_enc.fit_transform(X_ord_cat)\n",
        "\n",
        "print(\"Original Ordinal Data:\\n\", X_ord_cat)\n",
        "print(\"Ordinal Encoded Data:\\n\", X_ord_encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Ordinal Data:\n",
            " [['small']\n",
            " ['medium']\n",
            " ['large']\n",
            " ['medium']\n",
            " ['small']]\n",
            "Ordinal Encoded Data:\n",
            " [[1.]\n",
            " [0.]\n",
            " [2.]\n",
            " [0.]\n",
            " [1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2e5edb9"
      },
      "source": [
        "Maps categories to integers while preserving their inherent order. Requires specifying the order of categories.\n",
        "Only suitable when a meaningful order exists between categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e7d1026"
      },
      "source": [
        "### 4. Target Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e224805f"
      },
      "source": [
        "Target encoding replaces each category with the mean of the target variable for that category. This often requires the `category_encoders` library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aef2fe3",
        "outputId": "5fc445d1-17d7-49dc-8540-2599f9cafd0b"
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.8.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.16.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (0.14.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "Downloading category_encoders-2.8.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f221c375",
        "outputId": "550aa4b3-28e6-4293-9858-c58ff250cebd"
      },
      "source": [
        "import category_encoders as ce\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Sample categorical feature and a numerical target variable\n",
        "X_cat = pd.DataFrame({'Color': ['red', 'blue', 'green', 'red', 'blue', 'green', 'red']})\n",
        "y_target = pd.Series([10, 15, 12, 11, 16, 14, 9]) # Example numerical target\n",
        "\n",
        "# Apply Target Encoding\n",
        "encoder = ce.TargetEncoder(cols=['Color'])\n",
        "X_target_encoded = encoder.fit_transform(X_cat, y_target)\n",
        "\n",
        "print(\"Original Data:\")\n",
        "print(X_cat)\n",
        "print(\"\\nTarget Data:\")\n",
        "print(y_target)\n",
        "print(\"\\nTarget Encoded Data:\")\n",
        "print(X_target_encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data:\n",
            "   Color\n",
            "0    red\n",
            "1   blue\n",
            "2  green\n",
            "3    red\n",
            "4   blue\n",
            "5  green\n",
            "6    red\n",
            "\n",
            "Target Data:\n",
            "0    10\n",
            "1    15\n",
            "2    12\n",
            "3    11\n",
            "4    16\n",
            "5    14\n",
            "6     9\n",
            "dtype: int64\n",
            "\n",
            "Target Encoded Data:\n",
            "       Color\n",
            "0  12.053441\n",
            "1  12.864257\n",
            "2  12.509629\n",
            "3  12.053441\n",
            "4  12.864257\n",
            "5  12.509629\n",
            "6  12.053441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66cbf5ae"
      },
      "source": [
        "Replaces categories with a statistic based on the target variable. Can reduce dimensionality and capture information about the target.\n",
        "Requires careful handling to avoid target leakage (using validation sets for encoding)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e4ef587"
      },
      "source": [
        "### 5. Binary Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a9d31e4"
      },
      "source": [
        "Binary encoding converts categories to binary digits. It's a compromise between Label Encoding and One-Hot Encoding, reducing dimensionality compared to One-Hot Encoding while avoiding the artificial order of Label Encoding. This can also be done with the `category_encoders` library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2552a594"
      },
      "source": [
        "### 5. Binary Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a83edc1c"
      },
      "source": [
        "Binary encoding converts categories to binary digits. It's a compromise between Label Encoding and One-Hot Encoding, reducing dimensionality compared to One-Hot Encoding while avoiding the artificial order of Label Encoding. This can also be done with the `category_encoders` library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb9e70b9",
        "outputId": "fae5c934-e4dc-48b5-dad1-8cfca88648f9"
      },
      "source": [
        "import category_encoders as ce\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Sample categorical data\n",
        "X_cat = pd.DataFrame({'Color': ['red', 'blue', 'green', 'red', 'blue', 'green', 'red', 'yellow']})\n",
        "\n",
        "print(\"Original Data:\")\n",
        "print(X_cat)\n",
        "print(\"-\" * 30) # Separator for clarity\n",
        "\n",
        "# Apply Binary Encoding\n",
        "# This will create new columns representing the binary code for each color.\n",
        "# The number of new columns will be log2(number of unique colors).\n",
        "encoder = ce.BinaryEncoder(cols=['Color'])\n",
        "X_binary_encoded = encoder.fit_transform(X_cat)\n",
        "\n",
        "print(\"Binary Encoded Data:\")\n",
        "print(X_binary_encoded)\n",
        "\n",
        "print(\"-\" * 30) # Separator for clarity\n",
        "print(\"Explanation of Binary Encoding:\")\n",
        "print(\"Each unique color is assigned a unique binary code.\")\n",
        "print(\"The columns Color_0, Color_1, etc. represent the binary digits.\")\n",
        "print(\"For example, if 'red' is encoded as 001:\")\n",
        "print(\"- Rows with 'red' in 'Original Data' will have 0 in 'Color_0', 0 in 'Color_1', and 1 in 'Color_2' in 'Binary Encoded Data'.\")\n",
        "print(\"Observe the patterns in the 'Binary Encoded Data' to see the binary codes for each color.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data:\n",
            "    Color\n",
            "0     red\n",
            "1    blue\n",
            "2   green\n",
            "3     red\n",
            "4    blue\n",
            "5   green\n",
            "6     red\n",
            "7  yellow\n",
            "------------------------------\n",
            "Binary Encoded Data:\n",
            "   Color_0  Color_1  Color_2\n",
            "0        0        0        1\n",
            "1        0        1        0\n",
            "2        0        1        1\n",
            "3        0        0        1\n",
            "4        0        1        0\n",
            "5        0        1        1\n",
            "6        0        0        1\n",
            "7        1        0        0\n",
            "------------------------------\n",
            "Explanation of Binary Encoding:\n",
            "Each unique color is assigned a unique binary code.\n",
            "The columns Color_0, Color_1, etc. represent the binary digits.\n",
            "For example, if 'red' is encoded as 001:\n",
            "- Rows with 'red' in 'Original Data' will have 0 in 'Color_0', 0 in 'Color_1', and 1 in 'Color_2' in 'Binary Encoded Data'.\n",
            "Observe the patterns in the 'Binary Encoded Data' to see the binary codes for each color.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b340513e",
        "outputId": "e8c4e3ae-700d-4520-96fe-f43ea2a94a4d"
      },
      "source": [
        "# 1. Linear Regression (Scikit-learn)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([[1], [2], [3], [4]])\n",
        "y = np.array([2, 4, 5, 4])\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "prediction = model.predict([[5]])\n",
        "print(f\"Prediction: {prediction[0]:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 5.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f139d7aa"
      },
      "source": [
        "*   Uses Scikit-learn for a simple linear regression model.\n",
        "*   Trains the model on sample data and makes a prediction.\n",
        "*   Demonstrates the ease of use of Scikit-learn for classical ML."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52df25d3",
        "outputId": "449895b6-ea79-4690-a136-69c0d0bfde41"
      },
      "source": [
        "# 2. Standardization (Z-score Scaling)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([[0], [2], [3], [4], [10]])\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "print(\"Standardized Data:\\n\", X_scaled)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standardized Data:\n",
            " [[-1.12744258]\n",
            " [-0.53405175]\n",
            " [-0.23735633]\n",
            " [ 0.05933908]\n",
            " [ 1.83951157]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ee12604"
      },
      "source": [
        "*   Applies standardization to scale features using Scikit-learn.\n",
        "*   Transforms data to have a mean of 0 and standard deviation of 1.\n",
        "*   Helps improve performance for algorithms sensitive to feature scales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cee82b90",
        "outputId": "6e1d697d-0f14-496c-af14-43fb23d421f4"
      },
      "source": [
        "# 3. One-Hot Encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "X_cat = np.array([['red'], ['blue'], ['green']])\n",
        "ohe = OneHotEncoder(sparse_output=False)\n",
        "X_ohe = ohe.fit_transform(X_cat)\n",
        "print(\"One-Hot Encoded Data:\\n\", X_ohe)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-Hot Encoded Data:\n",
            " [[0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d21cd42a"
      },
      "source": [
        "*   Converts categorical data into a numerical format.\n",
        "*   Creates binary columns for each category to avoid artificial order.\n",
        "*   Essential for models that require numerical input."
      ]
    }
  ]
}